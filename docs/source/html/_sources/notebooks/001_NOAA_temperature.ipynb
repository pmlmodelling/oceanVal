{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9f533356",
   "metadata": {},
   "source": [
    "# Sea surface temperature validation using gridded observations from NOAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4644d99",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "variable = \"temperature\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a68d5a",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import importlib\n",
    "import re\n",
    "import warnings\n",
    "import calendar\n",
    "import copy\n",
    "import oceanval\n",
    "ff  = \"../../matched/definitions.pkl\"\n",
    "import pickle\n",
    "with open(ff, \"rb\") as f:\n",
    "    definitions = pickle.load(f)\n",
    "\n",
    "import glob\n",
    "import geopandas as gpd\n",
    "import jellyfish\n",
    "import nctoolkit as nc\n",
    "nc.options(parallel=True)\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from IPython.display import Markdown as md_markdown\n",
    "import cmocean as cm\n",
    "from tqdm import tqdm\n",
    "import hvplot.pandas\n",
    "from plotnine import *\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from oceanval.tidiers import tidy_info\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "try:\n",
    "    lon_lim = None\n",
    "    lat_lim = None\n",
    "except:\n",
    "    lon_lim = None\n",
    "    lat_lim = None\n",
    "if lon_lim is None:\n",
    "    lon_lim = [-180, 180]\n",
    "if lat_lim is None:\n",
    "    lat_lim = [-90, 90]\n",
    "\n",
    "try:\n",
    "    concise = False\n",
    "except:\n",
    "    concise = False\n",
    "\n",
    "# in one line\n",
    "from oceanval.tidiers import fix_basename, fix_unit, df_display, tidy_summary_paths, md, md_basic\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%load_ext rpy2.ipython\n",
    "\n",
    "test_status = False\n",
    "\n",
    "\n",
    "i_figure = 1\n",
    "i_table = 1\n",
    "stamp = nc.session_info[\"stamp\"]\n",
    "out = \".trackers/\" + stamp\n",
    "fast_plot = False\n",
    "if not os.path.exists(\".trackers\"):\n",
    "    os.makedirs(\".trackers\")\n",
    "# save out as empty file\n",
    "with open(out, 'w') as f:\n",
    "    f.write(\"\")\n",
    "nws = False\n",
    "\n",
    "def bin_value(x, bin_res):\n",
    "    return np.floor((x + bin_res / 2) / bin_res + 0.5) * bin_res - bin_res / 2\n",
    "\n",
    "try:\n",
    "    vv_name = variable\n",
    "except:\n",
    "    vv_name = \"summary\"\n",
    "    variable = \"summary\"\n",
    "Variable = variable.title()\n",
    "if vv_name in [\"benbio\"]:\n",
    "    compact = True\n",
    "try:\n",
    "    vv_name = definitions[variable].long_name \n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a87e968",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "stamp = nc.session_info[\"stamp\"]\n",
    "out = \".trackers/\" + stamp + \".txt\"\n",
    "if not os.path.exists(\".trackers\"):\n",
    "    os.makedirs(\".trackers\")\n",
    "# save out as empty file\n",
    "with open(out, 'w') as f:\n",
    "    f.write(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165557df",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "source = \"NOAA\"\n",
    "#domain = [x for x in glob.glob(f\"../../matched/gridded/**/**/**_{variable.lower()}*.nc\") if source in x][0].split(\"/\")[-3]\n",
    "domain = \"nws\"\n",
    "sub_regions = \"global\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d20026",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "ff = glob.glob(f\"../../matched/gridded/**/**_{variable.lower()}_*surface.nc\")\n",
    "ff_def = ff[0].replace(\".nc\", \"_definitions.pkl\")\n",
    "with open(ff_def, \"rb\") as f:\n",
    "    definitions = pickle.load(f)\n",
    "model_variable = definitions[variable].model_variable    \n",
    "md(f\"**Matchup procedure**: The model and observations were matched up as follows. First, the model dataset was cropped by a small amount to make sure cells close to the boundary were removed. The model was then regridded to the observational grid if the observational grid was coarser using nearest neighbour. Only grid cells with model and observational data were maintained. The following model output was used to compare with the observational values: **{model_variable}**.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647fa244",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "ff = [x for x in ff if f\"{source}_\" in x]\n",
    "try:\n",
    "    ff_summary = glob.glob(os.path.dirname(ff[0]) + \"/*summary.pkl\")[0]\n",
    "    with open(ff_summary, 'rb') as f:\n",
    "        vv_summary = pickle.load(f)\n",
    "    clim_years = summary[\"clim\"]\n",
    "    clim_years = \" (\" + str(clim_years[0]) + \"-\" + str(clim_years[1]) + \") \"\n",
    "except:\n",
    "    clim_years = \"\"\n",
    "    pass\n",
    "\n",
    "if len(ff) != 1:\n",
    "    raise ValueError(\"Something is wrong with the file\")\n",
    "layer = os.path.basename(ff[0]).split(\"_\")[-1].replace(\".nc\", \"\")\n",
    "if layer == \"surface\":\n",
    "    layer_long = \"sea surface\"\n",
    "ff_vertical = ff[0].replace(\"_surface.nc\", \"_vertical.nc\")\n",
    "ds_model = nc.open_data(ff)\n",
    "ds_model.subset(lon = lon_lim, lat = lat_lim)\n",
    "# change the long_name\n",
    "ds_model.set_precision(\"F32\")\n",
    "ds_model.subset(variable = \"model\")\n",
    "ds_model.tmean(\"month\")\n",
    "ds_model.run()\n",
    "new_name = definitions[variable].long_name \n",
    "new_name = new_name[0].upper() + new_name[1:]   \n",
    "ds_model.set_longnames({ds_model.variables[0]: new_name})\n",
    "ds_year = min(ds_model.years)\n",
    "ds_model.set_year(ds_year)\n",
    "ds_times = ds_model.times\n",
    "df_times = pd.DataFrame({\"year\":[x.year for x in ds_times]}).groupby(\"year\").size().reset_index()\n",
    "df_times.columns = [\"year\", \"count\"]\n",
    "years = list(df_times.query(\"count > 1\").year)\n",
    "ds_model.as_missing(0)\n",
    "# if variable is doc, add 40\n",
    "ds_model.run()\n",
    "ds_annual = ds_model.copy()\n",
    "ds_annual.tmean()\n",
    "# ds_annual.set_longnames({ds_annual.variables[0]: Variable})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b478825b",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "md(\"## Baseline climatologies of sea surface temperature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bcec28",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# model climatology years can be derived from the vv_summary\n",
    "try:\n",
    "    clim_years = vv_summary[\"clim_years\"]\n",
    "    if clim_years[0] == clim_years[-1]:\n",
    "        clim_text = f\" The model climatology is calculated using the year **{clim_years[0]}**.\"\n",
    "        clim_range = f\" ({clim_years[0]}) \"\n",
    "    else:\n",
    "        clim_text = f\" The model climatology is calculated using the years **{clim_years[0]}-{clim_years[-1]}**.\"\n",
    "        clim_range = f\" ({clim_years[0]}-{clim_years[-1]}) \"\n",
    "except:\n",
    "    clim_text = \"\"\n",
    "    clim_range = \"\"\n",
    "    pass\n",
    "md_markdown(f\"Climatologies of model and observational {layer_long} {vv_name} are shown in the figures below.{clim_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45c20a2",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "ff = glob.glob(f\"../../matched/gridded/**/**_{variable}_*surface.nc\")\n",
    "ff = [x for x in ff if f\"{source}_\" in x]\n",
    "ds_obs = nc.open_data(ff)\n",
    "ds_obs.subset(variable = \"observation\")\n",
    "ds_obs.subset(lon = lon_lim, lat = lat_lim)\n",
    "\n",
    "ds_obs.run()\n",
    "# changte the long_name\n",
    "new_name = definitions[variable].long_name\n",
    "new_name = new_name[0].upper() + new_name[1:]   \n",
    "ds_obs.set_longnames({ds_obs.variables[0]: new_name})\n",
    "ds_obs.set_precision(\"F32\")\n",
    "ds_obs.tmean(\"month\")\n",
    "ds_obs.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126cad5c",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6308613",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if variable == \"chlorophyll\":\n",
    "    transformation = \"log10\"\n",
    "else:\n",
    "    transformation = None \n",
    "\n",
    "\n",
    "ds_annual = ds_model.copy()\n",
    "ds_annual.tmean()\n",
    "# if \"model\" == ds_annual.variables[0]:\n",
    "#     ds_annual.set_longnames({\"model\": Variable})\n",
    "# else:\n",
    "#     ds_annual.set_longnames({variable: Variable})\n",
    "\n",
    "ds_annual.run()\n",
    "\n",
    "#get the min/max lon lat with actual values in ds_annual\n",
    "# save as [lon_min, lon_max] and [lat_min, lat_max]\n",
    "coord_ranges = (\n",
    "    ds_annual\n",
    "    .to_dataframe()\n",
    "    .reset_index()\n",
    "    .dropna()\n",
    ")\n",
    "lon_name = [x for x in coord_ranges.columns if \"lon\" in x][0]\n",
    "lat_name = [x for x in coord_ranges.columns if \"lat\" in x][0]\n",
    "coord_ranges = (\n",
    "    coord_ranges\n",
    "    # rename the columns to lon and lat\n",
    "    .rename(columns = {lon_name: \"lon\", lat_name: \"lat\"})\n",
    "    #\n",
    "    .loc[:,[\"lon\", \"lat\"]]\n",
    "    .agg([\"min\", \"max\"])\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "lon_min = coord_ranges[\"lon\"][\"min\"]\n",
    "lon_max = coord_ranges[\"lon\"][\"max\"]\n",
    "lat_min = coord_ranges[\"lat\"][\"min\"]\n",
    "lat_max = coord_ranges[\"lat\"][\"max\"]\n",
    "if lon_max < 90:\n",
    "    ds_annual.subset(lon = [lon_min, lon_max], lat = [lat_min, lat_max])\n",
    "fix_grid = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b885730",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Plot them on the same scale\n",
    "ds_both = ds_model.copy()\n",
    "ds_both.rename({ds_both.variables[0]: \"model\"})\n",
    "ds_both.append(ds_obs)\n",
    "ds_both.rename({ds_obs.variables[0]: \"observation\"})\n",
    "ds_both.merge(match = \"month\")\n",
    "ds_both.run()\n",
    "ds_both.variables\n",
    "\n",
    "#get the min/max lon lat with actual values in ds_annual\n",
    "# save as [lon_min, lon_max] and [lat_min, lat_max]\n",
    "coord_ranges = (\n",
    "    ds_both\n",
    "    .to_dataframe()\n",
    "    .reset_index()\n",
    "    .dropna()\n",
    ")\n",
    "lon_name = [x for x in coord_ranges.columns if \"lon\" in x][0]\n",
    "lat_name = [x for x in coord_ranges.columns if \"lat\" in x][0]\n",
    "coord_ranges = (\n",
    "    coord_ranges\n",
    "    # rename the columns to lon and lat\n",
    "    .rename(columns = {lon_name: \"lon\", lat_name: \"lat\"})\n",
    "    #\n",
    "    .loc[:,[\"lon\", \"lat\"]]\n",
    "    .agg([\"min\", \"max\"])\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "lat_min = coord_ranges[\"lat\"][\"min\"]\n",
    "lat_max = coord_ranges[\"lat\"][\"max\"]\n",
    "if lon_max < 90:\n",
    "    ds_both.subset(lon = [lon_min, lon_max], lat = [lat_min, lat_max])\n",
    "\n",
    "if fix_grid:\n",
    "    ds_both.to_latlon(lon = [lon_min , lon_max], lat = [lat_min, lat_max], res = [lon_res, lat_res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f19083",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.subplots_adjust(wspace=20, hspace=20)\n",
    "\n",
    "fig = plt.figure(figsize=(14, 14))\n",
    "\n",
    "# Create 1x2 Grid\n",
    "\n",
    "gs = fig.add_gridspec(nrows=1, ncols=2, wspace = 0.35, hspace = 0)\n",
    "\n",
    "# get limits..\n",
    "\n",
    "ds_both.tmean()\n",
    "\n",
    "z_min = (\n",
    "    ds_both\n",
    "    .to_dataframe()\n",
    "    .reset_index()\n",
    "    .dropna()\n",
    "    .loc[:,[\"model\", \"observation\"]]\n",
    "    # get the 2nd percentils\n",
    "    # .groupby(\"variable\")\n",
    "    .quantile(0.02)\n",
    "    .min()\n",
    ")\n",
    "\n",
    "# get the 98th percentils\n",
    "\n",
    "z_max = (\n",
    "    ds_both\n",
    "    .to_dataframe()\n",
    "    .reset_index()\n",
    "    .dropna()\n",
    "    .loc[:,[\"model\", \"observation\"]]\n",
    "    .quantile(0.98)\n",
    "    .max()\n",
    ")\n",
    "# fix the units\n",
    "\n",
    "ds_both.set_units({\"observation\": ds_both.contents.query(\"variable == 'model'\").reset_index().unit.values[0]})\n",
    "# chang longname\n",
    "# try:\n",
    "#     ds_both.set_longnames({\"observation\": ds_both.contents.query(\"variable == 'model'\").reset_index().long_name.values[0]}) \n",
    "# except:\n",
    "#     ds_both.set_longnames({\"observation\": ds_both.contents.query(\"variable == 'observation'\").reset_index().long_name.values[0]})  \n",
    "# ditch #Modelled and Observed from long names\n",
    "the_contents = ds_both.contents\n",
    "for vv in the_contents.variable:\n",
    "    long_name = the_contents.query(f\"variable == '{vv}'\").reset_index().long_name.values[0]\n",
    "    if \"Modelled\" in long_name:\n",
    "        long_name = long_name.replace(\"Modelled\", \"\").strip().replace(\"surface\", \"Surface\")\n",
    "    if \"Observed\" in long_name:\n",
    "        long_name = long_name.replace(\"Observed\", \"\").strip().replace(\"surface\", \"Surface\")\n",
    "    ds_both.set_longnames({vv: new_name})\n",
    "\n",
    "ds_both.pub_plot(variable  = \"model\", limits = [z_min, z_max], title = \"Model\", fig = fig, gs = gs[0,0], trans = transformation)\n",
    "\n",
    "\n",
    "\n",
    "ds_both.pub_plot(variable  = \"observation\", limits = [z_min, z_max], title = \"Observation\", fig = fig, gs = gs[0,1], trans = transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b11a7f",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "fig\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfc9c1d",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "md(f\"**Figure {i_figure}**: Annual average {layer} {vv_name} from the model {clim_range} and observations. Data is limited to the 2nd and 98th percentile of the combined model and observational data. Arrows indicate that values can exceed the colorbar limits.\") \n",
    "i_figure += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33fbf56",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14fafad",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "md(f\"## Assessing model bias for {layer} {vv_name}\")\n",
    "#\n",
    "# A critical metric for model performance is the bias between model and observed values. Here the bias is calculated as the mean difference between model and observed values. A positive bias indicates that the model overestimates the observed values, while a negative bias indicates that the model underestimates the observed values. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7930da",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "ds_bias = ds_model.copy()\n",
    "ds_bias - ds_obs\n",
    "ds_bias.tmean()\n",
    "ds_bias.run()\n",
    "# model plot\n",
    "\n",
    "df_bias = ds_bias.to_dataframe().reset_index()\n",
    "if \"model\" == ds_bias.variables[0]:\n",
    "    ds_bias.set_longnames({\"model\": Variable + \" bias\"})\n",
    "else:\n",
    "    ds_bias.set_longnames({variable: Variable + \" bias\"})\n",
    "\n",
    "# get th\n",
    "ds_ave = ds_bias.copy()\n",
    "ds_ave.spatial_mean()\n",
    "ds_ave.rename({ds_ave.variables[0]: \"bias\"})\n",
    "ave_bias = ds_ave.to_dataframe().bias.values[0]\n",
    "ds_summary = ds_bias.copy()\n",
    "ds_summary > 0 \n",
    "ds_summary.spatial_mean()\n",
    "ds_summary.rename({ds_summary.variables[0]: \"bias\"})\n",
    "positive_bias = ds_summary.to_dataframe().bias.values[0] * 100\n",
    "# as a percentage to 1 dp\n",
    "positive_bias = round(positive_bias, 1)\n",
    "the_unit = ds_summary.contents.unit.values[0]\n",
    "\n",
    "md(f\"Figure {i_figure} shows the average bias of {layer} {vv_name} simulated by the model. A positive bias indicates that the model overestimates the observation, while a negative bias indicates that the model overpredicts the observation.\") \n",
    "if positive_bias > 50:\n",
    "    positive_bias = str(positive_bias) + \"%\"\n",
    "    md(f\"The spatial average bias of {layer} {vv_name} is {ave_bias:.2f} {the_unit}. Overall, the model overestimates the observations in {positive_bias} of the model domain.\")\n",
    "else:\n",
    "    negative_bias = str(100-positive_bias) + \"%\"\n",
    "    md(f\"The spatial average bias of {layer} {vv_name} is {ave_bias:.2f} {the_unit}. Overall, the model underestimates the observations in {negative_bias} of the model domain.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c955a6",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "if fix_grid:\n",
    "    ds_bias_1 = ds_bias.copy()\n",
    "    ds_bias_1.to_latlon(lon = [lon_min , lon_max], lat = [lat_min, lat_max], res = [lon_res, lat_res])\n",
    "    # change the name\n",
    "    ds_bias_1.set_longnames({ds_bias_1.variables[0]: \"Model bias\"})\n",
    "    ds_bias_1.pub_plot(robust = True)\n",
    "else:\n",
    "    # change the name\n",
    "    ds_bias.set_longnames({ds_bias.variables[0]: \"Model bias\"})\n",
    "    ds_bias.pub_plot(robust = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ca5144",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "md(f\"**Figure {i_figure}**: Bias of {layer} {vv_name} from the model. A positive bias indicates that the model overestimates the observation.  For clarity, the colorbar is limited to the 2nd and 98th percentile of the data.\")\n",
    "i_figure += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa9db9d",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "md(f\"## Can the model reproduce seasonality of {layer_long} {vv_name}?\")\n",
    "\n",
    "md(f\"The ability of the model to reproduce seasonality of {layer_long} {vv_name} was assessed by comparing the modelled and observed seasonal cycle of {vv_name}. First, we derive a monthly climatology for the model data. Then, we calculate the Pearson correlation coefficient between the modelled and observed {vv_name} at each grid cell.\")\n",
    "\n",
    "\n",
    "md(\"Note: we are only assessing the ability of the model to reproduce the ability of the model to reproduce seasonal changes, not long-term trends.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4cce76",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4893bf1",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "ds1 = ds_model.copy()\n",
    "ds1.cdo_command(\"setname,model\")\n",
    "ds1.run()\n",
    "ds2 = ds_obs.copy()\n",
    "ds2.cdo_command(\"setname,observation\")\n",
    "ds2.run()\n",
    "ds_cor = nc.open_data([ds1.current[0], ds2.current[0]])\n",
    "ds_cor.merge(match=[\"month\"])\n",
    "ds_cor.run()\n",
    "ds_ts = ds_cor.copy()\n",
    "ds_cor.cor_time(\"model\", \"observation\")\n",
    "title = f\"Seasonal temporal correlation between {variable} for model and observations\"\n",
    "ds_cor.run()\n",
    "\n",
    "# output to nc\n",
    "\n",
    "out = f\"../../results/temporals/{variable}_cor_{source}.nc\"\n",
    "if not os.path.exists(os.path.dirname(out)):\n",
    "    os.makedirs(os.path.dirname(out))\n",
    "ds_cor.to_nc(out, zip = True, overwrite = True)\n",
    "\n",
    "# output to csv\n",
    "\n",
    "if False:\n",
    "    df_cor = ds_cor.to_dataframe().reset_index()\n",
    "    df_cor = df_cor.dropna()\n",
    "    out = f\"../../results/temporals/{variable}_cor_{source}.csv\"\n",
    "    if not os.path.exists(os.path.dirname(out)):\n",
    "        os.makedirs(os.path.dirname(out))\n",
    "    df_cor.to_csv(out, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42be653",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "df_cor = ds_cor.to_dataframe().reset_index()\n",
    "if fix_grid:\n",
    "    ds_cor_plot = ds_cor.copy()\n",
    "    ds_cor_plot.to_latlon(lon = [lon_min , lon_max], lat = [lat_min, lat_max], res = [lon_res, lat_res])\n",
    "    ds_cor_plot.pub_plot(\"cor\")\n",
    "else:\n",
    "    ds_cor.pub_plot(\"cor\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa3cc56",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "md(f\"**Figure {i_figure}**: Seasonal temporal correlation between model and observations for {layer} {vv_name}. This is the Pearson correlation coefficient between climatological monthly mean values in the model and observations.\")\n",
    "i_figure += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06eb928e",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "lon_range = lon_max - lon_min\n",
    "lat_range = lat_max - lat_min\n",
    "\n",
    "global_grid = False\n",
    "if lon_range > 340:\n",
    "    if lat_range > 160:\n",
    "        global_grid = True\n",
    "\n",
    "\n",
    "data_path = str(importlib.resources.files(\"oceanval\").joinpath(f\"data/{sub_regions}_subdomains.nc\"))\n",
    "\n",
    "regional = False\n",
    "\n",
    "if sub_regions in [\"nwes\", \"global\"]: \n",
    "    ds_regions = nc.open_data(data_path, checks = False)\n",
    "    if os.path.exists(data_path):\n",
    "        regional = True\n",
    "    # pull this in from the package data\n",
    "    \n",
    "    ds_regions.as_missing(0)\n",
    "    ds_regions.set_fill(-9999)\n",
    "    ds_regions.run()\n",
    "    ds_regions.regrid(ds_model, method = \"nn\")\n",
    "    regions_contents = ds_regions.contents\n",
    "    \n",
    "    # figure out if you can sensibly do a regional analysis for nws\n",
    "    grid = pd.read_csv(\"../../matched/model_grid.csv\")\n",
    "    lon = grid.loc[:,[x for x in grid.columns if \"lon\" in x]].values\n",
    "    lon = np.unique(lon)\n",
    "    lon.sort()\n",
    "    lat = grid.loc[:,[x for x in grid.columns if \"lat\" in x]].values\n",
    "    lat = np.unique(lat)\n",
    "    lat.sort()\n",
    "    # get unique values in grid and sort them\n",
    "    lon = np.unique(lon)\n",
    "    lon.sort()\n",
    "    lon_min = lon.min()\n",
    "    lon_max = lon.max()\n",
    "    lat_min = lat.min()\n",
    "    lat_max = lat.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1d5884",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f477e389",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "#shape = gpd.read_file(f\"{data_dir}/mapping/TM_WORLD_BORDERS-0.3.shp\")\n",
    "mod_var = ds_model.variables[0]\n",
    "obs_var = ds_obs.variables[0]\n",
    "# create xlim using mod_var\n",
    "try:\n",
    "    time_name = [x for x in list(ds_model.to_xarray().coords) if \"time\" in x][0]\n",
    "except:\n",
    "    time_name = None\n",
    "    concise = True\n",
    "if len(ds_model.times) == 1:\n",
    "    concise = True\n",
    "    time_name = None\n",
    "    model_unit = \"\"\n",
    "    raw_extent = \"foo\"\n",
    "    xlim = \"bar\"\n",
    "    ylim = \"ba\"\n",
    "if time_name is not None:\n",
    "    lon_name = [x for x in list(ds_obs.to_xarray().coords) if \"lon\" in x][0]\n",
    "    lat_name = [x for x in list(ds_obs.to_xarray().coords) if \"lat\" in x][0]\n",
    "\n",
    "    df_model = (\n",
    "        ds_model\n",
    "        .to_dataframe()\n",
    "        .reset_index()\n",
    "        .rename(columns = {time_name: \"time\"})\n",
    "        .rename(columns = {lon_name: \"lon\"})\n",
    "        .rename(columns = {lat_name: \"lat\"})\n",
    "        .assign(month = lambda x: x.time.dt.month)\n",
    "        .loc[:,[\"lon\", \"lat\", \"month\", mod_var ]]\n",
    "        .rename(columns = {mod_var: \"model\"})\n",
    "        .dropna()\n",
    "    )\n",
    "\n",
    "    xlim = np.array([df_model.lon.min(), df_model.lon.max()])\n",
    "    ylim = np.array([df_model.lat.min(), df_model.lat.max()])\n",
    "\n",
    "    df_obs = (\n",
    "        ds_obs\n",
    "        .to_dataframe()\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    time_name = [x for x in list(ds_obs.to_xarray().coords) if \"time\" in x][0]\n",
    "    lon_name = [x for x in list(ds_obs.to_xarray().coords) if \"lon\" in x][0]\n",
    "    lat_name = [x for x in list(ds_obs.to_xarray().coords) if \"lat\" in x][0]\n",
    "\n",
    "\n",
    "    df_obs = (\n",
    "        df_obs\n",
    "        .rename(columns = {time_name: \"time\"}  )\n",
    "        .rename(columns = {lon_name: \"lon\"}  )\n",
    "        .rename(columns = {lat_name: \"lat\"}  )\n",
    "        .assign(month = lambda x: x.time.dt.month)\n",
    "        .loc[:,[\"lon\", \"lat\", \"month\", obs_var ]]\n",
    "        .rename(columns = {obs_var: \"observation\"})\n",
    "        .dropna()\n",
    "\n",
    "    )\n",
    "\n",
    "    df_diff = (\n",
    "        df_model\n",
    "        .merge(df_obs, on = [\"lon\", \"lat\", \"month\"])\n",
    "        .assign(diff = lambda x: x.model - x.observation)\n",
    "    )\n",
    "    try:\n",
    "        model_unit = ds_model.contents.unit[0]\n",
    "        model_unit = fix_unit(model_unit)\n",
    "    except:\n",
    "        model_unit = ds_obs.contents.unit[0]\n",
    "        model_unit = fix_unit(model_unit)\n",
    "    from oceanval.utils import get_extent\n",
    "    raw_extent = get_extent(ds_annual[0])\n",
    "    if np.abs(raw_extent[0] - df_model.lon.min()) > 3:\n",
    "        # convert longitude to -180-180\n",
    "        df_model[\"lon\" ] = [x if x < 180 else x -360 for x in df_model.lon]\n",
    "        df_obs[\"lon\" ] = [x if x < 180 else x -360 for x in df_obs.lon]\n",
    "        df_diff[\"lon\" ] = [x if x < 180 else x -360 for x in df_diff.lon]\n",
    "\n",
    "    # generate a temporary csv file name in /tmp\n",
    "    # create adhoc dir if not\n",
    "    if not os.path.exists(\"adhoc/tmp\"):\n",
    "        os.makedirs(\"adhoc/tmp\")\n",
    "    tmp_csv = f\"adhoc/df_obs_model.csv\"\n",
    "    df_obs.to_csv(tmp_csv)\n",
    "    tmp_csv = f\"adhoc/df_model_model.csv\"\n",
    "    df_model.to_csv(tmp_csv)\n",
    "    tmp_csv = f\"adhoc/df_diff_model.csv\"\n",
    "    df_diff.to_csv(tmp_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7db862b",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "    if not concise:\n",
    "        md(f\"The seasonal cycles of simulated and observed {vv_name} are compared in Figure {i_figure} below. This figure shows the model and observation average in each month of the year, and the differences between the two each month\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04cc96f",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "%%R -i model_unit  -w 800 -h 600 -i variable -i raw_extent -i concise -r 100\n",
    "options(warn=-1)\n",
    "\n",
    "\n",
    "if(concise == FALSE){\n",
    "\n",
    "fixed_scale = \"False\"\n",
    "\n",
    "if(fixed_scale == \"False\"){\n",
    "    fixed_scale = FALSE\n",
    "}\n",
    "if(fixed_scale == \"True\"){\n",
    "    fixed_scale = TRUE\n",
    "}\n",
    "\n",
    "\n",
    "library(tidyverse, warn.conflicts = FALSE)\n",
    "library(cowplot, warn.conflicts = FALSE)\n",
    "#library(tidyr, warn.conflicts = FALSE)\n",
    "library(dplyr, warn.conflicts = FALSE)\n",
    "\n",
    "df_model <- read_csv(\"adhoc/df_model_model.csv\")\n",
    "\n",
    "\n",
    "min_month = min(df_model$month)\n",
    "if(\"month\" %in% colnames(df_model) & min_month < 7){\n",
    "\n",
    "    model_unit = str_replace(model_unit, \"/m\\\\^3\", \"m<sup>-3</sup>\")\n",
    "    model_unit <- str_replace(model_unit, \"/kg\", \"kg<sup>-1</sup>\")\n",
    "\n",
    "    df_model_raw <- drop_na(df_model)\n",
    "    df_obs <- read_csv(\"adhoc/df_obs_model.csv\")\n",
    "    df_diff <- read_csv(\"adhoc/df_diff_model.csv\")\n",
    "\n",
    "\n",
    "#df_model_raw <- drop_na(df_model)\n",
    "df_obs_raw <- drop_na(df_obs)\n",
    "df_diff_raw <- drop_na(df_diff)\n",
    "\n",
    "if (variable == \"temperature\" )\n",
    "    model_unit = \"°C\"\n",
    "\n",
    "df_model <- drop_na(df_model)\n",
    "df_model <- df_model %>%\n",
    "    filter(month %in% c(1,2,3,4,5,6))\n",
    "df_obs <- df_obs %>%\n",
    "    filter(month %in% c(1,2,3,4,5,6))\n",
    "df_diff <- df_diff %>%\n",
    "    filter(month %in% c(1,2,3,4,5,6))\n",
    "# \n",
    "\n",
    "df_model_raw %>%\n",
    "    group_by(month) %>%\n",
    "    summarize(model_98 = quantile(model, probs = 0.98)) %>%\n",
    "    ungroup() %>%\n",
    "    summarize(model_98 = mean(model_98)) %>%\n",
    "    ungroup() %>%\n",
    "    pull(model_98) -> model_98\n",
    "\n",
    "obs_98 <- df_obs_raw %>%\n",
    "    group_by(month) %>%\n",
    "    summarize(obs_98 = quantile(observation, probs = 0.98)) %>%\n",
    "    ungroup() %>%\n",
    "    summarize(obs_98 = mean(obs_98)) %>%\n",
    "    ungroup() %>%\n",
    "    pull(obs_98)\n",
    "\n",
    "if(fixed_scale){\n",
    "    model_98 = max(c(model_98, obs_98))\n",
    "    obs_98 = max(c(model_98, obs_98))\n",
    "    # calculate the 2nd percentile of model and obs\n",
    "    model_02 <- df_model_raw %>%\n",
    "        group_by(month) %>%\n",
    "        summarize(model_02 = quantile(model, probs = 0.02)) %>%\n",
    "        ungroup() %>%\n",
    "        summarize(model_02 = mean(model_02)) %>%\n",
    "        ungroup() %>%\n",
    "        pull(model_02)\n",
    "    obs_02 <- df_obs_raw %>%\n",
    "        group_by(month) %>%\n",
    "        summarize(obs_02 = quantile(observation, probs = 0.02)) %>%\n",
    "        ungroup() %>%\n",
    "        summarize(obs_02 = mean(obs_02)) %>%\n",
    "        ungroup() %>%\n",
    "        pull(obs_02)\n",
    "    model_02 = min(c(model_02, obs_02))\n",
    "    obs_02 = min(c(model_02, obs_02))\n",
    "\n",
    "}\n",
    "\n",
    "df_model <- df_model %>%\n",
    "    mutate(model = ifelse(model > model_98, model_98, model))\n",
    "\n",
    "df_obs <- df_obs %>%\n",
    "    mutate(observation = ifelse(observation > obs_98, obs_98, observation))\n",
    "if (fixed_scale){\n",
    "    df_model <- df_model %>%\n",
    "        mutate(model = ifelse(model < model_02, model_02, model))\n",
    "\n",
    "    df_obs <- df_obs %>%\n",
    "        mutate(observation = ifelse(observation < obs_02, obs_02, observation))\n",
    "}\n",
    "\n",
    "diff_02 <- df_diff_raw %>%\n",
    "    group_by(month) %>%\n",
    "    summarize(diff_02 = quantile(diff, probs = 0.02)) %>% \n",
    "    ungroup() %>%\n",
    "    summarize(diff_02 = mean(diff_02)) %>%\n",
    "    ungroup() %>%\n",
    "    pull(diff_02)\n",
    "\n",
    "diff_98 <- df_diff_raw %>%\n",
    "    group_by(month) %>%\n",
    "    summarize(diff_98 = quantile(diff, probs = 0.98)) %>%\n",
    "    ungroup() %>%\n",
    "    summarize(diff_98 = mean(diff_98)) %>%\n",
    "    ungroup() %>%\n",
    "    pull(diff_98)\n",
    "\n",
    "df_diff <- df_diff %>% \n",
    "    mutate(diff = ifelse(diff < diff_02, diff_02, diff)) %>%\n",
    "    mutate(diff = ifelse(diff > diff_98, diff_98, diff))\n",
    "\n",
    "\n",
    "\n",
    "xlim = c(min(df_model$lon), max(df_model$lon))\n",
    "ylim = c(min(df_model$lat), max(df_model$lat))\n",
    "\n",
    "world_map <- map_data(\"world\") \n",
    "\n",
    "# get 98th percentile of df_model$\n",
    "\n",
    "# function to convert month number in int to month name\n",
    "month_name <- function(x){\n",
    "    month.abb[x]\n",
    "}\n",
    "\n",
    "# vectorize month_name function\n",
    "# \n",
    "month_name <- Vectorize(month_name) \n",
    "\n",
    "\n",
    "\n",
    "# convert month number to month name in dataframes\n",
    "\n",
    "# \n",
    "\n",
    "df_model <- df_model %>%\n",
    "    mutate(month = month_name(month))\n",
    "\n",
    "df_obs <- df_obs %>%\n",
    "    mutate(month = month_name(month))\n",
    "\n",
    "df_diff <- df_diff %>%\n",
    "    mutate(month = month_name(month))\n",
    "\n",
    "# first six months of the year in dataframes\n",
    "\n",
    "df_model <- df_model %>%\n",
    "    filter(month %in% c(\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\"))\n",
    "\n",
    "df_obs <- df_obs %>%\n",
    "    filter(month %in% c(\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\"))\n",
    "\n",
    "df_diff <- df_diff %>%  \n",
    "    filter(month %in% c(\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\"))\n",
    "\n",
    "\n",
    "# change month to suitable factor in dataframes\n",
    "\n",
    "df_model$month <- factor(df_model$month, levels = c(\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\"))\n",
    "\n",
    "df_obs$month <- factor(df_obs$month, levels = c(\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\"))\n",
    "\n",
    "df_diff$month <- factor(df_diff$month, levels = c(\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\"))\n",
    "\n",
    "\n",
    "# Create sensible lon/lat labels based on the min/min lon and lat\n",
    "# This needs to work on any data, including global data\n",
    "lon_breaks = c(xlim[1], xlim[1] + 10, 0, xlim[2] - 10)\n",
    "lat_breaks = c(ylim[1], ylim[1] + 5, ylim[1] + 10, ylim[1] + 15, ylim[2])\n",
    "lon_labels = c(paste0(round(xlim[1]), \"°W\"), paste0(round(xlim[1] + 10), \"°W\"), \"0°\", paste0(round(xlim[2] - 10), \"°E\"))\n",
    "lat_labels = c(paste0(round(ylim[1]), \"°N\"), paste0(round(ylim[1] + 5), \"°N\"), paste0(round(ylim[1] + 10), \"°N\"), paste0(round(ylim[1] + 15), \"°N\"), paste0(round(ylim[2]), \"°N\"))\n",
    "\n",
    "\n",
    "gg1 = ggplot(df_model)+\n",
    "    geom_tile(aes(x = lon, y = lat, fill = model))+\n",
    "    facet_wrap(~month, ncol = 6)+\n",
    "    coord_cartesian(xlim = xlim, ylim = ylim, expand = FALSE)+ \n",
    "    theme_bw(base_size = 12)+\n",
    "    theme(legend.title = ggtext::element_markdown(angle = -90), legend.title.align = 0.5)+\n",
    "    scale_fill_viridis_c(guide  = guide_colourbar(title.position = \"right\"))+\n",
    "    labs(x = NULL, y = NULL, title = \"Model\", fill = model_unit)\n",
    "\n",
    "\n",
    "gg1 <- gg1 +\n",
    "    # remove the x and y axis totally\n",
    "    theme(axis.text.x = element_blank(), axis.text.y = element_blank(),\n",
    "          axis.ticks.x = element_blank(), axis.ticks.y = element_blank(),\n",
    "          axis.title.x = element_blank(), axis.title.y = element_blank()) +\n",
    "    labs(x = \"\", y = \"\") \n",
    "\n",
    "gg1 <- gg1 + \n",
    "    geom_polygon(data = world_map, aes(x = long, y = lat, group = group), fill = \"grey\", colour = \"grey\")\n",
    "\n",
    "gg2 = ggplot(df_obs)+\n",
    "    geom_tile(aes(x = lon, y = lat, fill = observation))+\n",
    "    facet_wrap(~month, ncol = 6)+\n",
    "    coord_cartesian(xlim = xlim, ylim = ylim, expand = FALSE)+ \n",
    "    scale_fill_viridis_c(guide  = guide_colourbar(title.position = \"right\"))+\n",
    "    theme_bw(base_size = 12)+\n",
    "    theme(legend.title = ggtext::element_markdown(angle = -90), legend.title.align = 0.5)+\n",
    "    labs(x = NULL, y = NULL, title = \"Observation\", fill = model_unit)\n",
    "\n",
    "\n",
    "gg2 <- gg2 +\n",
    "    # remove the x and y axis totally\n",
    "    theme(axis.text.x = element_blank(), axis.text.y = element_blank(),\n",
    "          axis.ticks.x = element_blank(), axis.ticks.y = element_blank(),\n",
    "          axis.title.x = element_blank(), axis.title.y = element_blank()) +\n",
    "    labs(x = \"\", y = \"\") \n",
    "\n",
    "gg2 <-  gg2 + \n",
    "    geom_polygon(data = world_map, aes(x = long, y = lat, group = group), fill = \"grey\", colour = \"grey\")\n",
    "\n",
    "gg3 = ggplot(df_diff)+\n",
    "geom_tile(aes(x = lon, y = lat, fill = diff))+\n",
    "facet_wrap(~month, ncol = 6)+\n",
    "coord_cartesian(xlim = xlim, ylim = ylim, expand = FALSE)+ \n",
    "theme_bw(base_size = 12)+\n",
    "scale_fill_gradient2(guide  = guide_colourbar(title.position = \"right\"), low = \"blue\", high = \"red\")+\n",
    "theme(legend.title = ggtext::element_markdown(angle = -90), legend.title.align = 0.5)+\n",
    "labs(x = NULL, y = NULL, title = \"Model - Observation\", fill = model_unit)\n",
    "\n",
    "\n",
    "gg3 <- gg3 +\n",
    "    # remove the x and y axis totally\n",
    "    theme(axis.text.x = element_blank(), axis.text.y = element_blank(),\n",
    "          axis.ticks.x = element_blank(), axis.ticks.y = element_blank(),\n",
    "          axis.title.x = element_blank(), axis.title.y = element_blank()) +\n",
    "    labs(x = \"\", y = \"\") \n",
    "\n",
    "\n",
    "gg3 <- gg3 + \n",
    "        geom_polygon(data = world_map, aes(x = long, y = lat, group = group), fill = \"grey\", colour = \"grey\")\n",
    "\n",
    "\n",
    "cowplot::plot_grid(gg1, gg2, gg3, ncol = 1)\n",
    "\n",
    "}\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592b252e",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "%%R -i model_unit -w 800 -h 600 -i variable -i raw_extent -i concise -r 100\n",
    "options(warn=-1)\n",
    "\n",
    "if (concise == FALSE){\n",
    "\n",
    "    fixed_scale = \"False\"   \n",
    "    if (fixed_scale == \"False\")\n",
    "        fixed_scale = FALSE\n",
    "    if (fixed_scale == \"True\")\n",
    "        fixed_scale = TRUE\n",
    "    \n",
    "library(tidyverse, warn.conflicts = FALSE)\n",
    "library(cowplot, warn.conflicts = FALSE)\n",
    "library(dplyr, warn.conflicts = FALSE)\n",
    "\n",
    "df_model <- read_csv(\"adhoc/df_model_model.csv\")\n",
    "\n",
    "max_month = max(df_model$month)\n",
    "if(\"month\" %in% colnames(df_model) & max_month > 6){\n",
    "\n",
    "    df_model_raw <- drop_na(df_model)\n",
    "    df_obs <- read_csv(\"adhoc/df_obs_model.csv\")\n",
    "    df_diff <- read_csv(\"adhoc/df_diff_model.csv\")\n",
    "\n",
    "\n",
    "df_obs_raw <- drop_na(df_obs)\n",
    "df_diff_raw <- drop_na(df_diff)\n",
    "\n",
    "if (variable == \"temperature\" )\n",
    "    model_unit = \"°C\"\n",
    "\n",
    "    model_unit = str_replace(model_unit, \"/m\\\\^3\", \"m<sup>-3</sup>\")\n",
    "    # fix /kg to kg^-2\n",
    "    model_unit <- str_replace(model_unit, \"/kg\", \"kg<sup>-1</sup>\")\n",
    "\n",
    "df_model <- drop_na(df_model)\n",
    "df_model <- df_model %>%\n",
    "    filter(month > 6) \n",
    "df_obs <- df_obs %>%\n",
    "    filter(month > 6) \n",
    "df_diff <- df_diff %>%\n",
    "    filter(month > 6) \n",
    "\n",
    "df_model_raw %>%\n",
    "    group_by(month) %>%\n",
    "    summarize(model_98 = quantile(model, probs = 0.98)) %>%\n",
    "    ungroup() %>%\n",
    "    summarize(model_98 = mean(model_98)) %>%\n",
    "    ungroup() %>%\n",
    "    pull(model_98) -> model_98\n",
    "\n",
    "obs_98 <- df_obs_raw %>%\n",
    "    group_by(month) %>%\n",
    "    summarize(obs_98 = quantile(observation, probs = 0.98)) %>%\n",
    "    ungroup() %>%\n",
    "    summarize(obs_98 = mean(obs_98)) %>%\n",
    "    ungroup() %>%\n",
    "    pull(obs_98)\n",
    "\n",
    "if (fixed_scale){\n",
    "    model_98 = max(c(model_98, obs_98))\n",
    "    obs_98 = max(c(model_98, obs_98))\n",
    "    # calculate the 2nd percentile of model and obs\n",
    "    model_02 <- df_model_raw %>%\n",
    "        group_by(month) %>%\n",
    "        summarize(model_02 = quantile(model, probs = 0.02)) %>%\n",
    "        ungroup() %>%\n",
    "        summarize(model_02 = mean(model_02)) %>%\n",
    "        ungroup() %>%\n",
    "        pull(model_02)\n",
    "    obs_02 <- df_obs_raw %>%\n",
    "        group_by(month) %>%\n",
    "        summarize(obs_02 = quantile(observation, probs = 0.02)) %>%\n",
    "        ungroup() %>%\n",
    "        summarize(obs_02 = mean(obs_02)) %>%\n",
    "        ungroup() %>%\n",
    "        pull(obs_02)\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "df_model <- df_model %>%\n",
    "    mutate(model = ifelse(model > model_98, model_98, model))\n",
    "\n",
    "    if (fixed_scale){\n",
    "        df_model <- df_model %>%\n",
    "            mutate(model = ifelse(model < model_02, model_02, model))\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "df_obs <- df_obs %>%\n",
    "    mutate(observation = ifelse(observation > obs_98, obs_98, observation))\n",
    "\n",
    "if (fixed_scale){\n",
    "    df_obs <- df_obs %>%\n",
    "        mutate(observation = ifelse(observation < obs_02, obs_02, observation))\n",
    "    }\n",
    "\n",
    "diff_02 <- df_diff_raw %>%\n",
    "    group_by(month) %>%\n",
    "    summarize(diff_02 = quantile(diff, probs = 0.02)) %>% \n",
    "    ungroup() %>%\n",
    "    summarize(diff_02 = mean(diff_02)) %>%\n",
    "    ungroup() %>%\n",
    "    pull(diff_02)\n",
    "\n",
    "diff_98 <- df_diff_raw %>%\n",
    "    group_by(month) %>%\n",
    "    summarize(diff_98 = quantile(diff, probs = 0.98)) %>%\n",
    "    ungroup() %>%\n",
    "    summarize(diff_98 = mean(diff_98)) %>%\n",
    "    ungroup() %>%\n",
    "    pull(diff_98)\n",
    "\n",
    "df_diff <- df_diff %>% \n",
    "    mutate(diff = ifelse(diff < diff_02, diff_02, diff)) %>%\n",
    "    mutate(diff = ifelse(diff > diff_98, diff_98, diff))\n",
    "\n",
    "\n",
    "\n",
    "xlim = c(min(df_model$lon), max(df_model$lon))\n",
    "ylim = c(min(df_model$lat), max(df_model$lat))\n",
    "\n",
    "world_map <- map_data(\"world\") \n",
    "\n",
    "# get 98th percentile of df_model$\n",
    "\n",
    "# function to convert month number in int to month name\n",
    "month_name <- function(x){\n",
    "    month.abb[x]\n",
    "}\n",
    "\n",
    "# vectorize month_name function\n",
    "# \n",
    "month_name <- Vectorize(month_name) \n",
    "\n",
    "\n",
    "\n",
    "# convert month number to month name in dataframes\n",
    "\n",
    "# \n",
    "\n",
    "df_model <- df_model %>%\n",
    "    mutate(month = month_name(month))\n",
    "\n",
    "df_obs <- df_obs %>%\n",
    "    mutate(month = month_name(month))\n",
    "\n",
    "df_diff <- df_diff %>%\n",
    "    mutate(month = month_name(month))\n",
    "\n",
    "# first six months of the year in dataframes\n",
    "\n",
    "\n",
    "df_model <- df_model %>%    \n",
    "    filter(month %in% c(\"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"))\n",
    "\n",
    "df_obs <- df_obs %>%\n",
    "    filter(month %in% c(\"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"))\n",
    "\n",
    "df_diff <- df_diff %>%\n",
    "    filter(month %in% c(\"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"))\n",
    "\n",
    "# change month to suitable factor in dataframes\n",
    "\n",
    "df_model$month <- factor(df_model$month, levels = c(\"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"))\n",
    "\n",
    "df_obs$month <- factor(df_obs$month, levels = c(\"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"))\n",
    "\n",
    "df_diff$month <- factor(df_diff$month, levels = c(\"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"))\n",
    "\n",
    "# Create sensible lon/lat labels based on the min/min lon and lat\n",
    "# This needs to work on any data, including global data\n",
    "lon_breaks = c(xlim[1], xlim[1] + 10, 0, xlim[2] - 10)\n",
    "lat_breaks = c(ylim[1], ylim[1] + 5, ylim[1] + 10, ylim[1] + 15, ylim[2])\n",
    "lon_labels = c(paste0(round(xlim[1]), \"°W\"), paste0(round(xlim[1] + 10), \"°W\"), \"0°\", paste0(round(xlim[2] - 10), \"°E\"))\n",
    "lat_labels = c(paste0(round(ylim[1]), \"°N\"), paste0(round(ylim[1] + 5), \"°N\"), paste0(round(ylim[1] + 10), \"°N\"), paste0(round(ylim[1] + 15), \"°N\"), paste0(round(ylim[2]), \"°N\"))\n",
    "\n",
    "\n",
    "\n",
    "gg1 = ggplot(df_model)+\n",
    "geom_tile(aes(x = lon, y = lat, fill = model))+\n",
    "facet_wrap(~month, ncol = 6)+\n",
    "coord_cartesian(xlim = xlim, ylim = ylim, expand = FALSE)+ \n",
    "theme_bw(base_size = 12)+\n",
    "theme(legend.title = ggtext::element_markdown(angle = -90), legend.title.align = 0.5)+\n",
    "scale_fill_viridis_c(guide  = guide_colourbar(title.position = \"right\"))+\n",
    "labs(x = NULL, y = NULL, title = \"Model\", fill = model_unit)\n",
    "\n",
    "\n",
    "gg1 <- gg1 + \n",
    "        geom_polygon(data = world_map, aes(x = long, y = lat, group = group), fill = \"grey\", colour = \"grey\")\n",
    "\n",
    "gg1 <- gg1 +\n",
    "    # remove the x and y axis totally\n",
    "    theme(axis.text.x = element_blank(), axis.text.y = element_blank(),\n",
    "          axis.ticks.x = element_blank(), axis.ticks.y = element_blank(),\n",
    "          axis.title.x = element_blank(), axis.title.y = element_blank()) +\n",
    "    labs(x = \"\", y = \"\") \n",
    "\n",
    "\n",
    "gg2 = ggplot(df_obs)+\n",
    "geom_tile(aes(x = lon, y = lat, fill = observation))+\n",
    "facet_wrap(~month, ncol = 6)+\n",
    "coord_cartesian(xlim = xlim, ylim = ylim, expand = FALSE)+ \n",
    "scale_fill_viridis_c(guide  = guide_colourbar(title.position = \"right\"))+\n",
    "theme_bw(base_size = 12)+\n",
    "theme(legend.title = ggtext::element_markdown(angle = -90), legend.title.align = 0.5)+\n",
    "labs(x = NULL, y = NULL, title = \"Observation\", fill = model_unit)\n",
    "\n",
    "gg2 <- gg2 + \n",
    "        geom_polygon(data = world_map, aes(x = long, y = lat, group = group), fill = \"grey\", colour = \"grey\")\n",
    "\n",
    "gg2 <- gg2 +\n",
    "    # remove the x and y axis totally\n",
    "    theme(axis.text.x = element_blank(), axis.text.y = element_blank(),\n",
    "          axis.ticks.x = element_blank(), axis.ticks.y = element_blank(),\n",
    "          axis.title.x = element_blank(), axis.title.y = element_blank()) +\n",
    "    labs(x = \"\", y = \"\") \n",
    "\n",
    "gg3 = ggplot(df_diff)+\n",
    "geom_tile(aes(x = lon, y = lat, fill = diff))+\n",
    "facet_wrap(~month, ncol = 6)+\n",
    "coord_cartesian(xlim = xlim, ylim = ylim, expand = FALSE)+ \n",
    "theme_bw(base_size = 12)+\n",
    "scale_fill_gradient2(guide  = guide_colourbar(title.position = \"right\"), low = \"blue\", high = \"red\")+\n",
    "theme(legend.title = ggtext::element_markdown(angle = -90), legend.title.align = 0.5)+\n",
    "labs(x = NULL, y = NULL, title = \"Model - Observation\", fill = model_unit)\n",
    "\n",
    "\n",
    "gg3 <- gg3 + \n",
    "        geom_polygon(data = world_map, aes(x = long, y = lat, group = group), fill = \"grey\", colour = \"grey\")\n",
    "\n",
    "gg3 <- gg3 +\n",
    "    # remove the x and y axis totally\n",
    "    theme(axis.text.x = element_blank(), axis.text.y = element_blank(),\n",
    "          axis.ticks.x = element_blank(), axis.ticks.y = element_blank(),\n",
    "          axis.title.x = element_blank(), axis.title.y = element_blank()) +\n",
    "    labs(x = \"\", y = \"\") \n",
    "\n",
    "gg1 <- gg1 + \n",
    "   theme(plot.margin = margin(t = 0,  # Top margin\n",
    "                             r = 0,  # Right margin\n",
    "                             b = 0,  # Bottom margin\n",
    "                             l = 0)) # Left ggmargin \n",
    "\n",
    "# figure out if it's a global file\n",
    "if(abs(raw_extent[1] - raw_extent[2]) > 350){\n",
    "    gg1 <- gg1 + \n",
    "    scale_x_continuous(breaks = c(-180, -90, 0, 90, 180), labels = c(\"180°W\", \"90°W\", \"0°\", \"90°E\", \"180°E\"))+\n",
    "    scale_y_continuous(breaks = c(-90, -45, 0, 45, 90), labels = c(\"90°S\", \"45°S\", \"0°\", \"45°N\", \"90°N\"))\n",
    "\n",
    "    gg2 <- gg2 +\n",
    "    scale_x_continuous(breaks = c(-180, -90, 0, 90, 180), labels = c(\"180°W\", \"90°W\", \"0°\", \"90°E\", \"180°E\"))+\n",
    "    scale_y_continuous(breaks = c(-90, -45, 0, 45, 90), labels = c(\"90°S\", \"45°S\", \"0°\", \"45°N\", \"90°N\"))\n",
    "\n",
    "    gg3 <- gg3 +\n",
    "    scale_x_continuous(breaks = c(-180, -90, 0, 90, 180), labels = c(\"180°W\", \"90°W\", \"0°\", \"90°E\", \"180°E\"))+\n",
    "    scale_y_continuous(breaks = c(-90, -45, 0, 45, 90), labels = c(\"90°S\", \"45°S\", \"0°\", \"45°N\", \"90°N\"))\n",
    "\n",
    "}\n",
    "\n",
    "# appropriate plotting for nws \n",
    "if((raw_extent[1] > -30) & (raw_extent[2] < 20)){\n",
    "    gg1 <- gg1 + \n",
    "    scale_x_continuous(breaks = c(-20, -10, 0, 10), labels = c(\"20°W\", \"10°W\", \"0°\", \"10°E\"))+\n",
    "    scale_y_continuous(breaks = c(45, 50, 55, 60, 65), labels = c(\"45°N\", \"50°N\", \"55°N\", \"60°N\", \"65°N\"))\n",
    "    gg2 <- gg2 + \n",
    "    scale_x_continuous(breaks = c(-20, -10, 0, 10), labels = c(\"20°W\", \"10°W\", \"0°\", \"10°E\"))+\n",
    "    scale_y_continuous(breaks = c(45, 50, 55, 60, 65), labels = c(\"45°N\", \"50°N\", \"55°N\", \"60°N\", \"65°N\"))\n",
    "    gg3 <- gg3 +\n",
    "    scale_x_continuous(breaks = c(-20, -10, 0, 10), labels = c(\"20°W\", \"10°W\", \"0°\", \"10°E\"))+\n",
    "    scale_y_continuous(breaks = c(45, 50, 55, 60, 65), labels = c(\"45°N\", \"50°N\", \"55°N\", \"60°N\", \"65°N\"))\n",
    "}\n",
    "\n",
    "# gg1\n",
    "# reduce the size of the plot\n",
    "# options(repr.plot.width = 10, repr.plot.height = 3)\n",
    "# gg1\n",
    "cowplot::plot_grid(gg1, gg2, gg3, ncol = 1)\n",
    "\n",
    "}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfad5974",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if not concise:\n",
    "    fixed_scale = \"False\"\n",
    "    if fixed_scale == \"False\":\n",
    "        md(f\"**Figure {i_figure}**: Monthly mean {layer} {vv_name} for the model, observation and the difference between model and observations. For clarity, the maximum values are capped to the 98th percentiles\") \n",
    "    else:\n",
    "        md(f\"**Figure {i_figure}**: Monthly mean {layer} {vv_name} for the model, observation and the difference between model and observations. For clarity, the maximum and minimum values are capped to cover the 98th and 2nd percentiles of both model and observations.\")\n",
    "    i_figure += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528d3c68",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if concise:\n",
    "    regional = False\n",
    "if regional:\n",
    "    md(f\"## Regional assessment of model performance for {layer_long} {vv_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a330779f",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if regional:\n",
    "    md(\"We assessed the regional performance of the model by comparing the model with observations in a number of regions. The regions considered are mapped below.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d37725",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if regional:\n",
    "    lon_name = [x for x in ds_regions.to_xarray().coords if \"lon\" in x][0]\n",
    "    lat_name = [x for x in ds_regions.to_xarray().coords if \"lat\" in x][0]\n",
    "    df_mapped = (\n",
    "        ds_regions\n",
    "        .to_dataframe()\n",
    "        .reset_index()\n",
    "        # rename the columns\n",
    "        .rename(columns = {lon_name: \"lon\", lat_name: \"lat\"})\n",
    "        .melt(id_vars = [\"lon\", \"lat\"])\n",
    "        .dropna()\n",
    "        .merge(regions_contents.loc[:,[\"variable\", \"long_name\"]])\n",
    "        .drop(columns = [ \"value\"])\n",
    "    )\n",
    "    bad = [\"Rosa\", \"Locate Shelf\"]\n",
    "    df_mapped = df_mapped.query(\"long_name not in @bad\")\n",
    "    xlim = np.array([df_mapped.lon.min(), df_mapped.lon.max()])\n",
    "    ylim = np.array([df_mapped.lat.min(), df_mapped.lat.max()])\n",
    "\n",
    "    def fix_name(x):\n",
    "        x = x.replace(\"North East\", \"NE\")\n",
    "        x = x.replace(\"North \", \"N \")\n",
    "        if x == \"Channel\":\n",
    "            x = \"English Channel\"\n",
    "        return x\n",
    "\n",
    "    fix_name = np.vectorize(fix_name)\n",
    "\n",
    "\n",
    "    df_mapped.long_name = fix_name(df_mapped.long_name)\n",
    "\n",
    "else:\n",
    "    df_mapped = 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c28508",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "if regional:\n",
    "    df_all = []\n",
    "    df_summary = []\n",
    "    for vv in ds_regions.variables:\n",
    "        ds_rr = ds_regions.copy()\n",
    "        ds_rr.subset(variable = vv)\n",
    "        ds_rr.run()\n",
    "        ds_vv = ds_ts.copy()\n",
    "        time_name = [x for x in list(ds_vv.to_xarray().coords) if \"time\" in x][0]\n",
    "        ds_vv * ds_rr\n",
    "        ds_region = ds_vv.copy()\n",
    "        ds_cor = ds_vv.copy()\n",
    "        ds_cor.tmean()\n",
    "        ds_cor.cor_space(\"model\", \"observation\")\n",
    "        region = list(regions_contents.query(\"variable == @vv\").long_name)[0]\n",
    "        df1 = (\n",
    "            ds_cor\n",
    "            .to_dataframe()\n",
    "            .reset_index()\n",
    "            .loc[:,[\"cor\"]]\n",
    "            .rename(columns = {\"cor\": \"Spatial correlation\"})\n",
    "            .assign(region = region)\n",
    "        )\n",
    "        # now do the temporal correlation\n",
    "\n",
    "        ds_cor = ds_vv.copy()\n",
    "        ds_cor.cor_time(\"model\", \"observation\")\n",
    "        ds_cor.spatial_mean()\n",
    "        df2 = (\n",
    "            ds_cor\n",
    "            .to_dataframe()\n",
    "            .reset_index()\n",
    "            .loc[:,[\"cor\"]]\n",
    "            .rename(columns = {\"cor\": \"Temporal correlation\"})\n",
    "            .assign(region = region)\n",
    "        )\n",
    "        df = df1.merge(df2)\n",
    "\n",
    "        ds_vv.spatial_mean()\n",
    "        df_bias = (\n",
    "            ds_vv\n",
    "            .to_dataframe()\n",
    "            .reset_index()\n",
    "            .rename(columns = {time_name: \"time\"})\n",
    "            .loc[:,[\"time\", \"model\", \"observation\"]]\n",
    "            .assign(month = lambda x: x.time.dt.month)\n",
    "            .assign(bias = lambda x: x.model - x.observation)\n",
    "            .assign(region = region)\n",
    "            .groupby(\"region\")\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "            .loc[:,[\"region\", \"bias\"]]\n",
    "        )\n",
    "\n",
    "        # now add the RMSD, calculated in the same way as the bias\n",
    "        df_rmsd = (\n",
    "            ds_region\n",
    "            .to_dataframe()\n",
    "            .reset_index()\n",
    "            .rename(columns = {time_name: \"time\"})\n",
    "            .loc[:,[\"time\", \"model\", \"observation\"]]\n",
    "            .assign(month = lambda x: x.time.dt.month)\n",
    "            .assign(rmsd = lambda x: (x.model - x.observation)**2)\n",
    "            .assign(region = region)\n",
    "            .groupby(\"region\")\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "            .loc[:,[\"region\", \"rmsd\"]]\n",
    "            .assign(rmsd = lambda x: np.sqrt(x.rmsd))\n",
    "        )\n",
    "\n",
    "        df = df1.merge(df2).merge(df_bias).merge(df_rmsd)\n",
    "        df_summary.append(df)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        df_vv = (\n",
    "            ds_vv\n",
    "            .to_dataframe()\n",
    "            .reset_index()\n",
    "            .rename(columns = {time_name: \"time\"})\n",
    "            .loc[:,[\"time\", \"model\", \"observation\"]]\n",
    "            .melt(\"time\")\n",
    "            .assign(month = lambda x: x.time.dt.month)\n",
    "            .assign(region = vv)\n",
    "        )\n",
    "        df_all.append(df_vv)\n",
    "        ds_region.tmean()\n",
    "        df_region = (\n",
    "            ds_region\n",
    "            .to_dataframe()\n",
    "            .dropna()\n",
    "            .reset_index()\n",
    "            .loc[:,[\"model\", \"observation\"]]\n",
    "            .drop_duplicates()\n",
    "        )\n",
    "    \n",
    "        del ds_rr, ds_vv, ds_region\n",
    "    df_all = pd.concat(df_all).dropna()\n",
    "        \n",
    "    df_all = (\n",
    "        df_all\n",
    "        .merge(df_mapped.loc[:,[\"long_name\", \"variable\"]].drop_duplicates().rename(columns = {\"variable\": \"region\"}))\n",
    "    )\n",
    "    df_summary= pd.concat(df_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d062b1f0",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# restrict df_mapped to regions in df_all\n",
    "if regional:\n",
    "    regions = set(df_all.query(\"value > 0\").region)\n",
    "    df_mapped = df_mapped.query(\"variable in @regions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3287fa8",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "%%R -i regional -i df_mapped -i xlim -i ylim -i global_grid -w 800 -h 600\n",
    "options(warn=-1)\n",
    "\n",
    "if (regional){\n",
    "\n",
    "    library(tidyverse)\n",
    "\n",
    "    unique_long_names <- unique(df_mapped$long_name)\n",
    "    if(\"Full Domain\" %in% unique_long_names){\n",
    "        unique_long_names <- unique_long_names[unique_long_names != \"Full Domain\"]\n",
    "        # add Full Domain, but put it first\n",
    "        unique_long_names <- c(\"Full Domain\", unique_long_names)\n",
    "        df_mapped <- df_mapped %>%\n",
    "            mutate(long_name = factor(long_name, levels = unique_long_names)) \n",
    "    }\n",
    "\n",
    "    world_map <- map_data(\"world\")\n",
    "\n",
    "    gg <-  ggplot(df_mapped)+\n",
    "        geom_tile(aes(x = lon, y = lat))+\n",
    "        coord_cartesian(xlim = xlim, ylim = ylim, expand = FALSE)+\n",
    "        theme_bw(base_size = 12)+\n",
    "        facet_wrap(~long_name, ncol = 5)+\n",
    "        theme(axis.title.x = element_blank(),\n",
    "              axis.title.y = element_blank())\n",
    "\n",
    "\n",
    "gg <- gg +\n",
    "    # remove the x and y axis totally\n",
    "    theme(axis.text.x = element_blank(), axis.text.y = element_blank(),\n",
    "          axis.ticks.x = element_blank(), axis.ticks.y = element_blank(),\n",
    "          axis.title.x = element_blank(), axis.title.y = element_blank()) +\n",
    "    labs(x = \"\", y = \"\") \n",
    "\n",
    "gg <- gg + \n",
    "        geom_polygon(data = world_map, aes(x = long, y = lat, group = group), fill = \"grey\", color = \"grey\")\n",
    "\n",
    "\n",
    "\n",
    "    gg\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebc67b9",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if regional:\n",
    "    md(f\"**Figure {i_figure}**: Regions used for validation of {layer_long} {vv_name}.\")\n",
    "i_figure += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec3e2e8",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if regional:\n",
    "    md(f\"Time series were constructed comparing the monthly mean of the spatial average {layer_long} {vv_name} in each region. The spatial average was calculated using the mean of all grid cells within each region, accounting for grid cell area.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e077b12",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if regional:\n",
    "    out_ts = f\"../../results/regionals/{source}_{variable}_regionals.csv\"\n",
    "    # check if directory exists for out_ts\n",
    "    if not os.path.exists(\"../../results/regionals\"):\n",
    "        os.makedirs(\"../../results/regionals\")\n",
    "    df_all.to_csv(out_ts, index = False)\n",
    "if not regional:\n",
    "    df_all = False\n",
    "\n",
    "if regional:\n",
    "    try:\n",
    "        units = model_unit \n",
    "    except:\n",
    "        units = ds_ts.contents.unit[0]\n",
    "        units = str(units)\n",
    "\n",
    "else:\n",
    "    try:\n",
    "        units = model_unit\n",
    "    except:\n",
    "        units = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3d205e",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "%%R -i df_all -i regional -i vv_name -i units  -w 800 -h 600\n",
    "options(warn=-1)\n",
    "variable = vv_name\n",
    "\n",
    "# do a seasonal plot\n",
    "if(regional){\n",
    "\n",
    "    # convert long_name to factor\n",
    "    # unique_long_names \n",
    "    unique_long_names <- unique(df_all$long_name)\n",
    "    if(\"Full Domain\" %in% unique_long_names){\n",
    "        unique_long_names <- unique_long_names[unique_long_names != \"Full Domain\"]\n",
    "        # add Full Domain, but put it first\n",
    "        unique_long_names <- c(\"Full Domain\", unique_long_names)\n",
    "    df_all <- df_all %>%\n",
    "        mutate(long_name = factor(long_name, levels = unique_long_names)) \n",
    "    }\n",
    "\n",
    "    x_lab = str_glue(\"Spatial average {variable} ({units})\")\n",
    "    x_lab <- str_replace(x_lab, \"/m\\\\^3\", \"m<sup>-3</sup>\")\n",
    "    x_lab <- str_replace(x_lab, \"/m\\\\^2\", \"m<sup>-2</sup>\")\n",
    "    # handl /yr\n",
    "    x_lab <- str_replace(x_lab, \"/yr\", \" yr<sup>-1</sup>\")\n",
    "    # handle /m2\n",
    "    x_lab <- str_replace(x_lab, \"/m2\", \"m<sup>-2</sup>\")\n",
    "    # handle /m3\n",
    "    x_lab <- str_replace(x_lab, \"/m3\", \"m<sup>-3</sup>\")\n",
    "    # fix /kg to kg^-1\n",
    "    x_lab <- str_replace(x_lab, \"/kg\", \"kg<sup>-1</sup>\")\n",
    "    # CO2\n",
    "    x_lab <- str_replace(x_lab, \"CO2\", \"CO<sub>2</sub>\")\n",
    "    # O_2\n",
    "    x_lab <- str_replace(x_lab, \"O2\", \"O<sub>2</sub>\")\n",
    "    x_lab <- str_replace(x_lab, \"O_2\", \"O<sub>2</sub>\")\n",
    "    \n",
    "\n",
    "    library(tidyverse, warn.conflicts = FALSE)\n",
    "    library(ggplot2, warn.conflicts = FALSE)\n",
    "    library(ggridges, warn.conflicts = FALSE)\n",
    "    library(ggthemes, warn.conflicts = FALSE)\n",
    "    # make variable title\n",
    "    df_all = df_all %>%\n",
    "        mutate(variable = str_to_title(variable))\n",
    "\n",
    "    gg <- ggplot(df_all)+\n",
    "        geom_line(aes(x = month, y = value, colour = variable))+\n",
    "        facet_wrap(~long_name, ncol = 5)+\n",
    "        labs(y = x_lab)+\n",
    "        labs(x = \"Month\")+\n",
    "        theme(legend_position = \"top\")+\n",
    "        scale_color_manual(values = c(\"red\", \"blue\"))+\n",
    "        scale_x_continuous(breaks = c(1, 4, 7, 10), labels = c(\"Jan\", \"Apr\", \"Jul\", \"Oct\"))+ \n",
    "        theme_bw(base_size = 12)+\n",
    "        labs(colour = \"\")+\n",
    "        theme(legend.position = \"top\")+\n",
    "        theme(axis.title.y = ggtext::element_markdown())+\n",
    "        scale_color_fivethirtyeight()\n",
    "\n",
    "        gg\n",
    "\n",
    "\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db278d68",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if regional:\n",
    "    md(f\"**Figure {i_figure}**: Seasonal cycle of {layer_long} {vv_name} for model and observations for each region. The spatial average is taken over the region.\") \n",
    "    i_figure += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5437cd5",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if regional:\n",
    "    md(f\"The table below shows the average bias of sea surface {vv_name} in each region. The bias is calculated as the modelled value minus the observed value. A positive bias indicates that the model overestimates the observed value, while a negative bias indicates that the model underestimates the observed value.\")\n",
    "\n",
    "if regional:\n",
    "    # output and hide index\n",
    "    # first average things and tidy\n",
    "    df_summary = (\n",
    "        df_summary\n",
    "        # .loc[:,[\"region\", \"bias\"]]\n",
    "        .groupby(\"region\")\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "        # capitalize the columns\n",
    "        .rename(columns = {\"region\": \"Region\", \"bias\": \"Bias\", \"rmsd\": \"RMSD\"})\n",
    "    )\n",
    "    # remove na values\n",
    "    df_summary = df_summary.dropna().reset_index(drop = True)\n",
    "    if not global_grid:\n",
    "        # drop the spatial correlation\n",
    "        df_summary = df_summary.drop(columns = [\"Spatial correlation\"])\n",
    "    df_display(df_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b95f9fa",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if regional:\n",
    "    regional_summary = [f\"**Table {i_table}**: Summary of performance of the model sea surface {vv_name} in each region.\"]\n",
    "    regional_summary.append(f\"The bias ({model_unit}) column represents the spatial average of the annual mean modelled value minus the observed value.\")\n",
    "    regional_summary.append(\"The temporal correlation column represents the spatial mean of the temporal correlation between the model and observations per grid cell.\") \n",
    "    if global_grid:\n",
    "        regional_summary.append(\"The spatial correlation column represents the spatial correlation between the model and observations.\")\n",
    "    regional_summary = \" \".join(regional_summary).replace(\"  \", \" \")\n",
    "    md(regional_summary)\n",
    "    i_table = i_table + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a5c3ec",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c982d9e2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a92e0c",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "ds_annual = ds_model.copy()\n",
    "ds_annual.rename({ds_annual.variables[0]: \"model\"})\n",
    "ds_annual.append(ds_obs)\n",
    "ds_annual.tmean()\n",
    "ds_annual.merge(\"variables\")\n",
    "ds_annual.rename({ds_obs.variables[0]: \"observation\"})\n",
    "out_dir = \"../../results/annual_mean/\"\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "out_file = out_dir + f\"annualmean_{variable}_{source}.nc\"\n",
    "ds_annual.to_nc(out_file, zip = True, overwrite = True)\n",
    "# Calculate the monthly mean and output it\n",
    "\n",
    "ds_monthly = ds_model.copy()\n",
    "ds_monthly.rename({ds_monthly.variables[0]: \"model\"})\n",
    "ds_monthly.append(ds_obs)\n",
    "ds_monthly.tmean(\"month\")\n",
    "ds_monthly.merge(\"variables\", [\"month\"])\n",
    "ds_monthly.rename({ds_obs.variables[0]: \"observation\"})\n",
    "out_dir = \"../../results/monthly_mean/\"\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "out_file = out_dir + f\"monthlymean_{variable}_{source}.nc\"\n",
    "ds_monthly.to_nc(out_file, zip = True, overwrite = True)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7394e52e",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "md(f\"## Can the model reproduce spatial patterns of {layer_long} {vv_name}?\")\n",
    "\n",
    "md(f\"The ability of the model to reproduce spatial patterns of {layer_long} {vv_name} was assessed by comparing the modelled and observed {vv_name} at each grid cell. We calculated the Pearson correlation coefficient between the modelled and observed {vv_name} at each grid cell.\")\n",
    "md(\"This was carried out monthly and using the annual mean in each grid cell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acf4cb7",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "ff = glob.glob(f\"../../matched/gridded/**/**_{variable}*surface.nc\")\n",
    "ff = [x for x in ff if f\"{source}_\" in x]\n",
    "if len(ff) != 1:\n",
    "    raise ValueError(\"Something is wrong with the file\")\n",
    "layer = os.path.basename(ff[0]).split(\"_\")[-1].replace(\".nc\", \"\")\n",
    "ds_cor = nc.open_data(ff)\n",
    "ds_cor.subset(lon = lon_lim, lat = lat_lim)\n",
    "ds_cor.set_precision(\"F32\")\n",
    "ds_cor.tmean(\"month\")\n",
    "ds_cor.cor_space(\"model\", \"observation\")\n",
    "ds_cor_df = ds_cor.to_dataframe().reset_index()\n",
    "ds_cor_df = ds_cor_df.dropna()\n",
    "time_name = [x for x in list(ds_cor.to_xarray().coords) if \"time\" in x][0]\n",
    "# rename time in dataframe\n",
    "ds_cor_df.rename(columns = {time_name: \"time\"}, inplace = True)\n",
    "# extract the month\n",
    "ds_cor_df[\"month\"] = ds_cor_df.time.dt.month\n",
    "ds_cor_df = ds_cor_df.loc[:,[\"month\", \"cor\"]].drop_duplicates()\n",
    "# change month number to month name\n",
    "ds_cor_df[\"month\"] = ds_cor_df[\"month\"].apply(lambda x: calendar.month_abbr[x])\n",
    "# now do this annually\n",
    "ds_cor = nc.open_data(ff)\n",
    "ds_cor.subset(lon = lon_lim, lat = lat_lim)\n",
    "ds_cor.set_precision(\"F32\")\n",
    "ds_cor.tmean(\"month\")\n",
    "ds_cor.tmean()\n",
    "df_annual = ds_cor.to_dataframe()\n",
    "ds_cor.cor_space(\"model\", \"observation\")\n",
    "ds_cor_df_annual = ds_cor.to_dataframe().reset_index()\n",
    "ds_cor_df_annual = ds_cor_df_annual.dropna()\n",
    "time_name = [x for x in list(ds_cor.to_xarray().coords) if \"time\" in x][0]\n",
    "# rename time in dataframe\n",
    "ds_cor_df_annual.rename(columns = {time_name: \"time\"}, inplace = True)\n",
    "# extract the month\n",
    "ds_cor_df_annual[\"month\"] = ds_cor_df_annual.time.dt.month\n",
    "ds_cor_df_annual = ds_cor_df_annual.loc[:,[\"month\", \"cor\"]].drop_duplicates()\n",
    "# output to csv\n",
    "ds_cor_df_annual = ds_cor_df_annual.assign(month = \"Annual mean\")\n",
    "# merge the two dataframes\n",
    "ds_cor_df = pd.concat([ds_cor_df_annual, ds_cor_df])\n",
    "# change month to period\n",
    "ds_cor_df.rename(columns = {\"month\": \"period\"}, inplace = True)\n",
    "# Give the columns more sensible names\n",
    "ds_cor_df.rename(columns = {\"cor\": \"Correlation coefficient\"}, inplace = True)\n",
    "ds_cor_df.rename(columns = {\"period\": \"Time period\"}, inplace = True)\n",
    "# drop any na\n",
    "ds_cor_df.dropna(inplace = True)\n",
    "df_display(ds_cor_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01c398f",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "md(f\"**Table {i_table}**: Pearson correlation coefficient between modelled and observed {layer_long} {vv_name} at each grid cell. The correlation was calculated monthly and using the annual mean in each grid cell.\")\n",
    "i_table += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faff526",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "time_series = False\n",
    "if regional:\n",
    "    ff = glob.glob(f\"../../matched/gridded/**/**_{variable}*surface.nc\")\n",
    "    ff = [x for x in ff if f\"{source}_\" in x]\n",
    "    ds_ts = nc.open_data(ff)\n",
    "    ds_ts.subset(lon = lon_lim, lat = lat_lim)\n",
    "    years = ds_ts.years\n",
    "    year_range = f\"{min(years)}-{max(years)}\"\n",
    "    if len(years) > 1:\n",
    "        ds_ts.tmean(\"year\")\n",
    "        ds_ts.run()\n",
    "        time_series = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3b2cfc",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if time_series:\n",
    "    md(f\"The ability of the model to reproduce multi-year trends in {layer_long} {vv_name} was assessed by comparing the modelled and observed time series of annual {vv_name} across each region.\")\n",
    "    md(f\"The figure below shows the average {vv_name} in each region\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c41838c",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if time_series:\n",
    "    df_all = []\n",
    "    for vv in ds_regions.variables:\n",
    "        ds_rr = ds_regions.copy()\n",
    "        ds_rr.subset(variable = vv)\n",
    "        ds_rr.run()\n",
    "        ds_vv = ds_ts.copy()\n",
    "        ds_vv * ds_rr\n",
    "        ds_region = ds_vv.copy()\n",
    "        ds_vv.spatial_mean()\n",
    "        region = list(regions_contents.query(\"variable == @vv\").long_name)[0]\n",
    "        time_name = [x for x in list(ds_vv.to_xarray().coords) if \"time\" in x][0]\n",
    "        df_vv = (\n",
    "            ds_vv\n",
    "            .to_dataframe()\n",
    "            .reset_index()\n",
    "            .rename(columns = {time_name: \"time\"})\n",
    "            .loc[:,[\"time\", \"model\", \"observation\"]]\n",
    "            .melt(\"time\")\n",
    "            .assign(year = lambda x: x.time.dt.year)\n",
    "            .assign(region = vv)\n",
    "        )\n",
    "        df_all.append(df_vv)\n",
    "        ds_region.tmean()\n",
    "        df_region = (\n",
    "            ds_region\n",
    "            .to_dataframe()\n",
    "            .dropna()\n",
    "            .reset_index()\n",
    "            .loc[:,[\"model\", \"observation\"]]\n",
    "            .drop_duplicates()\n",
    "        )\n",
    "    \n",
    "        del ds_rr, ds_vv, ds_region\n",
    "    df_all = pd.concat(df_all).dropna()\n",
    "        \n",
    "    df_all = (\n",
    "        df_all\n",
    "        .merge(df_mapped.loc[:,[\"long_name\", \"variable\"]].drop_duplicates().rename(columns = {\"variable\": \"region\"}))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9eb4dd",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "%%R -i time_series -i variable -i df_all\n",
    "options(warn=-1)\n",
    "if(time_series){\n",
    "library(tidyverse)\n",
    "\n",
    "ylab = str_glue(\"Spatial average {variable} ({units})\")\n",
    "ylab <- str_replace(ylab, \"/m\\\\^3\", \"m<sup>-3</sup>\")\n",
    "ylab <- str_replace(ylab, \"/m\\\\^2\", \"m<sup>-2</sup>\")\n",
    "# handl /yr\n",
    "ylab <- str_replace(ylab, \"/yr\", \" yr<sup>-1</sup>\")\n",
    "# handle /m2\n",
    "ylab <- str_replace(ylab, \"/m2\", \"m<sup>2</sup>\")\n",
    "# handle /m3\n",
    "ylab <- str_replace(ylab, \"/m3\", \"m<sup>3</sup>\")\n",
    "# fix /kg to kg^-1\n",
    "ylab <- str_replace(ylab, \"/kg\", \"kg<sup>-1</sup>\")\n",
    "# CO2\n",
    "ylab <- str_replace(ylab, \"CO2\", \"CO<sub>2</sub>\")\n",
    "# make variable title\n",
    "# pco2\n",
    "ylab <- str_replace(ylab, \"pCO2\", \"pCO<sub>2</sub>\")\n",
    "ylab <- str_replace(ylab, \"pco2\", \"pCO<sub>2</sub>\")\n",
    "# mutam should use greek letters\n",
    "ylab <- str_replace(ylab, \"muatm\", \"µatm\")\n",
    "\n",
    "# create a suitable scale_x_continuous based on year\n",
    "# get the min and max year\n",
    "min_year = min(df_all$year)\n",
    "max_year = max(df_all$year)\n",
    "# create a sequence of years, maximum is 7\n",
    "ceiling((max_year - min_year)/7)\n",
    "seq_year <- seq(min_year, max_year, ceiling((max_year - min_year)/7))\n",
    "\n",
    "\n",
    "gg <- df_all %>%\n",
    "    ggplot(aes(x = year, y = value, colour = variable))+\n",
    "    geom_line()+\n",
    "    facet_wrap(~long_name)+\n",
    "    labs(y = ylab)+\n",
    "    labs(x = \"Year\")+\n",
    "    theme(legend.position = \"top\")+\n",
    "    scale_color_manual(values = c(\"red\", \"blue\"))+\n",
    "    theme_bw(base_size = 10)+\n",
    "    labs(colour = \"\")+\n",
    "    theme(legend.position = \"top\")+\n",
    "    theme(axis.title.y = ggtext::element_markdown())+\n",
    "    scale_color_fivethirtyeight()+\n",
    "    scale_x_continuous(breaks = seq_year, labels = seq_year)\n",
    "\n",
    "    gg\n",
    "\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df82c07b",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Now do the verticals if needed\n",
    "if os.path.exists(ff_vertical):\n",
    "    verticals = True\n",
    "    md(f\"## How well does the model reproduce vertical profiles of {vv_name}?\")\n",
    "    text = f\"The ability of the model to reproduce vertical profiles of {vv_name} was assessed by comparing the modelled and observed vertical profiles of {vv_name}. This was carried out by calculating the zonal average vertical profile of {vv_name} for both the model and observation based on annual means.\"\n",
    "    md(text)\n",
    "else:\n",
    "    verticals = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d7d1fc",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    regions = ds_regions.variables\n",
    "    # coerce to list\n",
    "    regions = list(regions)\n",
    "    regions.append(\"full_domain\")\n",
    "    regionals = True\n",
    "except:\n",
    "    regionals = True\n",
    "    regions = [\"full_domain\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda63af6",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if time_series:\n",
    "    md(f\"**Figure {i_figure}**: Changes in {layer_long} {vv_name} for model and observations for each region for the period {year_range}. The spatial average is taken over the region.\") \n",
    "    i_figure += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8595e91",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if verticals:\n",
    "    ds_verticals = nc.open_data(ff_vertical, checks = False)\n",
    "    ds_verticals.tmean()\n",
    "    ds_verticals.run()\n",
    "    levels = ds_verticals.levels\n",
    "    max_depth = max(levels)\n",
    "    min_depth = min(levels)\n",
    "    # 100 appropriate levels, evenly spaces\n",
    "    new_levels = np.linspace(min_depth, max_depth, 100)\n",
    "    ds_verticals.vertical_interp(new_levels, fixed = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11671e0e",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if verticals:\n",
    "    df_zonals = []\n",
    "    for rr in regions:\n",
    "        ds_rr = ds_verticals.copy()\n",
    "        if rr != \"full_domain\":\n",
    "            ds_subset = ds_regions.copy()\n",
    "            ds_subset.as_missing(0)\n",
    "            ds_subset.set_fill(-9999)\n",
    "            ds_subset.subset(variable = rr)\n",
    "            ds_subset.run()\n",
    "            long_name = ds_subset.contents.long_name[0]\n",
    "            ds_subset - 1\n",
    "            ds_rr + ds_subset\n",
    "            ds_rr.zonal_mean()\n",
    "        else:\n",
    "            ds_rr.zonal_mean()\n",
    "            long_name = \"Full domain\"\n",
    "        df_merged = ds_rr.to_dataframe().reset_index(drop = True)\n",
    "        depth_name = [x for x in ds_rr.to_xarray().coords if \"depth\" in x][0]\n",
    "        # rename\n",
    "        df_merged = df_merged.rename(columns = {depth_name: \"depth\"})\n",
    "        lon_name = [x for x in ds_rr.to_xarray().coords if \"lon\" in x][0]\n",
    "        lat_name = [x for x in ds_rr.to_xarray().coords if \"lat\" in x][0]\n",
    "        # ditch lon\n",
    "        df_merged = df_merged.drop(columns = [lon_name])\n",
    "        # rename lat to lat\n",
    "        df_merged = df_merged.rename(columns = {lat_name: \"lat\"})\n",
    "        df_merged = (\n",
    "            df_merged\n",
    "            # melt it\n",
    "            .melt(id_vars = [\"depth\", \"lat\"], value_vars = [\"model\", \"observation\"])\n",
    "        )\n",
    "        df_merged = (df_merged\n",
    "        # variable as title\n",
    "            .assign(variable = lambda x: x.variable.str.title())\n",
    "        ).assign(region = long_name) \n",
    "        df_zonals.append(df_merged)\n",
    "    df_zonals = pd.concat(df_zonals).dropna().reset_index(drop = True)\n",
    "\n",
    "    # Put Full domain first\n",
    "    df_zonals = pd.concat(\n",
    "        [df_zonals.query(\"region == 'Full domain'\"),\n",
    "        df_zonals.query(\"region != 'Full domain'\")]\n",
    "\n",
    "    )\n",
    "\n",
    "    \n",
    "    # only lat, model and observation\n",
    "    # df_rr = df_rr.loc[:,[lat_name, \"depth\", \"model\", \"observation\"]].dropna()\n",
    "else:\n",
    "    df_zonals = pd.DataFrame({\"foo\":[\"bar\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78921829",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "%%R -i verticals -i regionals -i df_zonals -i vv_name -i units -w 800 -h 2000\n",
    "# is df_zonals a dataframe\n",
    "\n",
    "if(\"region\" %in% colnames(df_zonals)){\n",
    "    library(tidyverse)\n",
    "    units <- str_replace(units, \"/m\\\\^3\", \"m<sup>-3</sup>\")\n",
    "    units <- str_replace(units, \"/m\\\\^2\", \"m<sup>-2</sup>\")\n",
    "    units <- str_replace(units, \"/yr\", \" yr<sup>-1</sup>\")\n",
    "    units <- str_replace(units, \"/m2\", \"m<sup>-2</sup>\")\n",
    "    units <- str_replace(units, \"/m3\", \"m<sup>-3</sup>\")\n",
    "    units <- str_replace(units, \"/kg\", \"kg<sup>-1</sup>\")\n",
    "    # CO2\n",
    "\n",
    "    # loop through the regions\n",
    "    i <- 1\n",
    "    big_list = list()\n",
    "    for(rr in unique(df_zonals$region)){\n",
    "\n",
    "    gg <- df_zonals %>%\n",
    "        filter(region == rr) %>%\n",
    "        drop_na() %>%\n",
    "        ggplot()+\n",
    "        geom_raster(aes(x = lat, y = depth, fill = value))+\n",
    "        facet_wrap(~variable)+\n",
    "        scale_y_reverse()+\n",
    "        scale_fill_viridis_c(guide  = guide_colourbar(title.position = \"right\"))+\n",
    "        theme_bw(base_size = 10)+\n",
    "        theme(legend.title = ggtext::element_markdown(angle = -90), legend.title.align = 0.5)+\n",
    "        labs(x = \"Latitude\", y = \"Depth (m)\", fill = str_glue(\"{vv_name} ({units})\"))+\n",
    "        theme(axis.title.y = ggtext::element_markdown())+\n",
    "        theme(axis.title.x = ggtext::element_markdown())+\n",
    "        coord_cartesian(expand = FALSE)+\n",
    "        # ditch the x axis labels\n",
    "\n",
    "        labs(x = \"\", title = rr)\n",
    "\n",
    "    x_breaks <- ggplot_build(gg)$layout$panel_params[[1]]$x$breaks\n",
    "    x_breaks <- na.omit(x_breaks)\n",
    "    x_labels <- paste0(x_breaks, \"°\")\n",
    "    # add N to x_label is x_break > 0\n",
    "    x_labels <- ifelse(x_breaks > 0, paste0(x_breaks, \"°N\"), ifelse(x_breaks < 0, paste0(abs(x_breaks), \"°S\"), \"0°\"))\n",
    "    # add S to x_label is x_break < 0\n",
    "    x_labels <- ifelse(x_breaks < 0, paste0(abs(x_breaks), \"°S\"), x_labels)\n",
    "    # remove  the str \"-\" from x_labels if x_break < 0\n",
    "    x_labels <- gsub(\"-\", \"\", x_labels)\n",
    "\n",
    "# no missing values\n",
    "    gg1 <- gg + scale_x_continuous(breaks = x_breaks, labels= x_labels)\n",
    "\n",
    "    # now do a bias plot\n",
    "    df_bias <- df_zonals %>%\n",
    "        filter(region == rr) %>%\n",
    "        drop_na() %>%\n",
    "        pivot_wider(names_from = variable, values_from = value) %>%\n",
    "        mutate(bias = Model - Observation)\n",
    "    gg2 <- df_bias %>%\n",
    "\n",
    "        ggplot()+\n",
    "        geom_raster(aes(x = lat, y = depth, fill = bias))+\n",
    "        scale_y_reverse()+\n",
    "        scale_fill_gradient2(low = \"blue\", mid = \"white\", high = \"red\", \n",
    "                             guide  = guide_colourbar(title.position = \"right\"))+\n",
    "        theme_bw(base_size = 10)+\n",
    "        theme(legend.title = ggtext::element_markdown(angle = -90), legend.title.align = 0.5)+\n",
    "        labs(x = \"Latitude\", y = \"Depth (m)\", fill = str_glue(\"Bias ({model_unit})\"))+\n",
    "        theme(axis.title.y = ggtext::element_markdown())+\n",
    "        theme(axis.title.x = ggtext::element_markdown())+\n",
    "        coord_cartesian(expand = FALSE)\n",
    "        # ditch the x axis labels\n",
    "    gg2 <- gg2 + labs(x = \"\")\n",
    "    x_breaks <- ggplot_build(gg2)$layout$panel_params[[1]]$x$breaks\n",
    "    x_breaks <- na.omit(x_breaks)\n",
    "    x_labels <- paste0(x_breaks, \"°\")\n",
    "    gg2 <- gg2 + scale_x_continuous(breaks = x_breaks, labels= x_labels)\n",
    "\n",
    "# combine the two plots, use rr as title\n",
    "    gg <- cowplot::plot_grid(gg1, gg2, ncol = 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    big_list[[i]] <- gg\n",
    "    i <- i + 1\n",
    "    \n",
    "    }\n",
    "\n",
    "    cowplot::plot_grid(plotlist = big_list, ncol = 1)\n",
    "\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7037ebe8",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if verticals and regionals:\n",
    "    md(f\"**Figure {i_figure}**: Vertical profiles of {layer_long} {vv_name} for model and observations for each region. The zonal average is taken over the region.\")\n",
    "    i_figure += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280efcca",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# delete all objects starting with ds\n",
    "for name in dir():\n",
    "    if name.startswith(\"ds\"):\n",
    "        del globals()[name]\n",
    "for name in dir():\n",
    "    if name.endswith(\"mask\"):\n",
    "        del globals()[name]\n",
    "nc.cleanup()\n",
    "for ff in nc.session.get_safe():\n",
    "    nc.session.remove_safe(ff)\n",
    "nc.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cbb9fe",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "md(f\"## Data Sources for validation of {vv_name}\")\n",
    "md_basic(definitions[variable].sources[source])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a95ea54",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if test_status:\n",
    "    md(\"This is getting to the end!\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
